
### Table of Contents

1. [Installation](#installation)
2. [Project Overview](#overview)
3. [File Descriptions](#files)
4. [Results](#results)
5. [Licensing, Authors, and Acknowledgements](#licensing)

## Installation <a name="installation"></a>

I use Anaconda with Python version 3.6 to create this ap with the following libraries Pandas, NumPy, Matplotlib, Scikit-Learn, Flask etc. Additionally I use Plotly library to create interactive visuals on web page.

To install this package with conda run:
conda install -c plotly plotly

## Project Overviewt<a name="overview"></a>
In this project,  disaster data from Figure Eight were analized to build a model for an API that classifies disaster messages.

The data set contains real messages that were sent during disaster events. The trained machine learning pipeline categorizes these events so that messages can be send to an appropriate disaster relief agency.

The web app displays visualizations of the data, allows to input message and address it to appropriate category.

1. What countries are major producers of the wine and what sorts of wine do have the highest rating in those countries?
2. What are the best rated wines in the different price category?
3. What is the most common description for the best rated wines produced in different countries?
4. How well the quality of wine can be predicted?

## File Descriptions <a name="files"></a>

1. wine-analysis.ipynb: notebook that showcases work to answer first three questions and includes the code for data cleaning, visualization.
2. ml-model.ipynb: notebook with machine learrning model to answer the question #4.
3. winemag-data-130k-v2.csv: contains 130k rows of wine reviews and 10 columns (description, designation, points, price, province, region_1, region_2, variety, winery.
4. Masks: a folder with masks of 12 most major wine producer countries downloaded from https://silhouettegarden.com/
5. WineWordcloud: a folder with 12 wordcloud country images generated by code wine-analysis.ipynb

## Instructions to run<a name="results"></a>
1. Run the following commands in the project's root directory to set up your database and model.

    - To run ETL pipeline that cleans data and stores in database
        `python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db`
    - To run ML pipeline that trains classifier and saves
        `python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl`

2. Run the following command in the app's directory to run your web app.
    `python run.py`

3. Go to http://0.0.0.0:3001/

## Licensing, Authors, Acknowledgements<a name="licensing"></a>

Thanks Udacity and Figure Eight for this project.
